{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf3756fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import arxiv\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "239401ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "if not GROQ_API_KEY:\n",
    "    print(\"Error: GROQ_API_KEY not found in .env file\")\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6da86a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 1: Environment Setup Complete ---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Step 1: Environment Setup Complete ---\\n\")\n",
    "\n",
    "# 2. Define our Goal\n",
    "QUERY = \"Agents\"\n",
    "MAX_RESULTS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cadcac90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 2: Searching ArXiv for 'Agents' ---\n"
     ]
    }
   ],
   "source": [
    "print(f\"--- Step 2: Searching ArXiv for '{QUERY}' ---\")\n",
    "\n",
    "# 3. Search ArXiv (The Raw Way)\n",
    "# We use the 'arxiv' library directly. No classes, just a client.\n",
    "client = arxiv.Client()\n",
    "search = arxiv.Search(\n",
    "    query=QUERY,\n",
    "    max_results=MAX_RESULTS,\n",
    "    sort_by=arxiv.SortCriterion.SubmittedDate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01e6317b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: Point Bridge: 3D Representations for Cross Domain Policy Learning\n",
      "Found: LLM-in-Sandbox Elicits General Agentic Intelligence\n",
      "Found: Average Unfairness in Routing Games\n",
      "Found: Delayed Assignments in Online Non-Centroid Clustering with Stochastic Arrivals\n",
      "Found: Controlling Long-Horizon Behavior in Language Model Agents with Explicit State Dynamics\n",
      "\n",
      "Total papers found: 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Store results in a simple list\n",
    "found_papers = []\n",
    "for result in client.results(search):\n",
    "    paper = {\n",
    "        \"title\": result.title,\n",
    "        \"summary\": result.summary,\n",
    "        \"url\": result.entry_id,\n",
    "        \"published\": result.published.strftime(\"%Y-%m-%d\")\n",
    "    }\n",
    "    found_papers.append(paper)\n",
    "    print(f\"Found: {paper['title']}\")\n",
    "\n",
    "print(f\"\\nTotal papers found: {len(found_papers)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "208304da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 3: AI Filtering ---\n"
     ]
    }
   ],
   "source": [
    "# 4. Filter with AI (The Logic)\n",
    "print(\"--- Step 3: AI Filtering ---\")\n",
    "\n",
    "# Setup the Model\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    api_key=GROQ_API_KEY,\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "311d6bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prompt tells the AI what to do\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a research assistant. Select papers relevant to the user's query.\"),\n",
    "    (\"user\", \"\"\"\n",
    "    User Query: {query}\n",
    "    \n",
    "    Here are the papers:\n",
    "    {papers}\n",
    "    \n",
    "    Return ONLY a JSON object with a key 'indices' containing the indices (0-based numbers) of the papers that are relevant.\n",
    "    Example: {{ \"indices\": [0, 2] }}\n",
    "    \"\"\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44679c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detailed paper text for the AI to read\n",
    "paper_text = \"\"\n",
    "for i, p in enumerate(found_papers):\n",
    "    paper_text += f\"Index {i}:\\nTitle: {p['title']}\\nSummary: {p['summary'][:200]}...\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b431de04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Index 0:\\nTitle: Point Bridge: 3D Representations for Cross Domain Policy Learning\\nSummary: Robot foundation models are beginning to deliver on the promise of generalist robotic agents, yet progress remains constrained by the scarcity of large-scale real-world manipulation datasets. Simulati...\\n\\nIndex 1:\\nTitle: LLM-in-Sandbox Elicits General Agentic Intelligence\\nSummary: We introduce LLM-in-Sandbox, enabling LLMs to explore within a code sandbox (i.e., a virtual computer), to elicit general intelligence in non-code domains. We first demonstrate that strong LLMs, witho...\\n\\nIndex 2:\\nTitle: Average Unfairness in Routing Games\\nSummary: We propose average unfairness as a new measure of fairness in routing games, defined as the ratio between the average latency and the minimum latency experienced by users. This measure is a natural co...\\n\\nIndex 3:\\nTitle: Delayed Assignments in Online Non-Centroid Clustering with Stochastic Arrivals\\nSummary: Clustering is a fundamental problem, aiming to partition a set of elements, like agents or data points, into clusters such that elements in the same cluster are closer to each other than to those in o...\\n\\nIndex 4:\\nTitle: Controlling Long-Horizon Behavior in Language Model Agents with Explicit State Dynamics\\nSummary: Large language model (LLM) agents often exhibit abrupt shifts in tone and persona during extended interaction, reflecting the absence of explicit temporal structure governing agent-level state. While ...\\n\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15756f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect the pieces: Prompt -> Model -> JSON Parser\n",
    "chain = prompt | llm | JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35de469f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke({\n",
    "    \"query\": QUERY,\n",
    "    \"papers\": paper_text\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59ab0ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'indices': [0, 1, 3, 4]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0557b9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 3, 4]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_indices = result.get(\"indices\", [])\n",
    "selected_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60cd460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Show Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1bbeb0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Final Selected Papers ---\n",
      "Title: Point Bridge: 3D Representations for Cross Domain Policy Learning\n",
      "Summary: Robot foundation models are beginning to deliver on the promise of generalist robotic agents, yet progress remains constrained by the scarcity of large-scale real-world manipulation datasets. Simulation and synthetic data generation offer a scalable alternative, but their usefulness is limited by the visual domain gap between simulation and reality. In this work, we present Point Bridge, a framework that leverages unified, domain-agnostic point-based representations to unlock synthetic datasets for zero-shot sim-to-real policy transfer, without explicit visual or object-level alignment. Point Bridge combines automated point-based representation extraction via Vision-Language Models (VLMs), transformer-based policy learning, and efficient inference-time pipelines to train capable real-world manipulation agents using only synthetic data. With additional co-training on small sets of real demonstrations, Point Bridge further improves performance, substantially outperforming prior vision-based sim-and-real co-training methods. It achieves up to 44% gains in zero-shot sim-to-real transfer and up to 66% with limited real data across both single-task and multitask settings. Videos of the robot are best viewed at: https://pointbridge3d.github.io/\n",
      "URL:   http://arxiv.org/abs/2601.16212v1\n",
      "---\n",
      "Title: LLM-in-Sandbox Elicits General Agentic Intelligence\n",
      "Summary: We introduce LLM-in-Sandbox, enabling LLMs to explore within a code sandbox (i.e., a virtual computer), to elicit general intelligence in non-code domains. We first demonstrate that strong LLMs, without additional training, exhibit generalization capabilities to leverage the code sandbox for non-code tasks. For example, LLMs spontaneously access external resources to acquire new knowledge, leverage the file system to handle long contexts, and execute scripts to satisfy formatting requirements. We further show that these agentic capabilities can be enhanced through LLM-in-Sandbox Reinforcement Learning (LLM-in-Sandbox-RL), which uses only non-agentic data to train models for sandbox exploration. Experiments demonstrate that LLM-in-Sandbox, in both training-free and post-trained settings, achieves robust generalization spanning mathematics, physics, chemistry, biomedicine, long-context understanding, and instruction following. Finally, we analyze LLM-in-Sandbox's efficiency from computational and system perspectives, and open-source it as a Python package to facilitate real-world deployment.\n",
      "URL:   http://arxiv.org/abs/2601.16206v1\n",
      "---\n",
      "Title: Delayed Assignments in Online Non-Centroid Clustering with Stochastic Arrivals\n",
      "Summary: Clustering is a fundamental problem, aiming to partition a set of elements, like agents or data points, into clusters such that elements in the same cluster are closer to each other than to those in other clusters. In this paper, we present a new framework for studying online non-centroid clustering with delays, where elements, that arrive one at a time as points in a finite metric space, should be assigned to clusters, but assignments need not be immediate. Specifically, upon arrival, each point's location is revealed, and an online algorithm has to irrevocably assign it to an existing cluster or create a new one containing, at this moment, only this point. However, we allow decisions to be postponed at a delay cost, instead of following the more common assumption of immediate decisions upon arrival. This poses a critical challenge: the goal is to minimize both the total distance costs between points in each cluster and the overall delay costs incurred by postponing assignments. In the classic worst-case arrival model, where points arrive in an arbitrary order, no algorithm has a competitive ratio better than sublogarithmic in the number of points. To overcome this strong impossibility, we focus on a stochastic arrival model, where points' locations are drawn independently across time from an unknown and fixed probability distribution over the finite metric space. We offer hope for beyond worst-case adversaries: we devise an algorithm that is constant competitive in the sense that, as the number of points grows, the ratio between the expected overall costs of the output clustering and an optimal offline clustering is bounded by a constant.\n",
      "URL:   http://arxiv.org/abs/2601.16091v1\n",
      "---\n",
      "Title: Controlling Long-Horizon Behavior in Language Model Agents with Explicit State Dynamics\n",
      "Summary: Large language model (LLM) agents often exhibit abrupt shifts in tone and persona during extended interaction, reflecting the absence of explicit temporal structure governing agent-level state. While prior work emphasizes turn-local sentiment or static emotion classification, the role of explicit affective dynamics in shaping long-horizon agent behavior remains underexplored. This work investigates whether imposing dynamical structure on an external affective state can induce temporal coherence and controlled recovery in multi-turn dialogue. We introduce an agent-level affective subsystem that maintains a continuous Valence-Arousal-Dominance (VAD) state external to the language model and governed by first- and second-order update rules. Instantaneous affective signals are extracted using a fixed, memoryless estimator and integrated over time via exponential smoothing or momentum-based dynamics. The resulting affective state is injected back into generation without modifying model parameters. Using a fixed 25-turn dialogue protocol, we compare stateless, first-order, and second-order affective dynamics. Stateless agents fail to exhibit coherent trajectories or recovery, while state persistence enables delayed responses and reliable recovery. Second-order dynamics introduce affective inertia and hysteresis that increase with momentum, revealing a trade-off between stability and responsiveness.\n",
      "URL:   http://arxiv.org/abs/2601.16087v1\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Final Selected Papers ---\")\n",
    "for idx in selected_indices:\n",
    "    if 0 <= idx < len(found_papers):\n",
    "        p = found_papers[idx]\n",
    "        print(f\"Title: {p['title']}\")\n",
    "        print(f\"Summary: {p['summary']}\")\n",
    "        print(f\"URL:   {p['url']}\")\n",
    "        print(\"---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
